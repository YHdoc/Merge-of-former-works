import heapq

def HeapifyDown(A,k):
	while 2*k+1<len(A):
		L,R=2*k+1,2*k+2
		if L<len(A) and A[L]<A[k]:mini=L
		else: mini=k
		if R<len(A) and A[R]<A[mini]:mini=R
		if mini!=k:
			A[k],A[mini]=A[mini],A[k]
			k=mini
		else:break
	
	
# def find_min(Alist):
# 	if len(Alist)==0: return None
# 	return Alist[0]

# def solve(A, k): # return k-th smallest key, 1 <= k <= n
# 	NewL=list()
# 	while len(A) != 0:
# 		# a=find_min(A)
# 		NewL.append(A[0])
# 		A[0],A[len(A)-1]=A[len(A)-1],A[0]
# 		A.pop()
# 		HeapifyDown(A,0)
# 		# heapq.heapify(A)
# 	# print(NewL)
# 	return NewL[k-1]

def solve(A,k):
	for i in range(len(A)):
		if i==k-1:break
		A[0],A[len(A)-1]=A[len(A)-1],A[0]
		A.pop()
		HeapifyDown(A,0)
	return A[0]

k = int(input())
A = [int(x) for x in input().split()]
heapq.heapify(A) # A is now a min-heap
print(solve(A, k))


# 주석
# -알고리즘 설명-
# 위 solve 함수의 실행 원리는 현재 힙이 최소힙이라고 가정했을 때, 입력한 수 k번째로 작은 수가 나올 때까지 그 힙에 존재하는 최솟값을 pop 하며 제거하는 것이다.
# 현재의 힙에서 최솟값이 pop된 후에도 힙 성질을 유지해야 한다. 원소가 하나 없어진 상태에서 리스트의 원소가 최소힙을 유지하도록 하는 작업이 필요한데, 위의 코드에서 HeapifyDown 함수가 이 역할을 수행한다.

# 1.solve 함수의 설명
# solve 함수는 heqpq.heapify()로 최소힙이 된 A리스트에서 k번째로 작은 숫자를 반환하는 함수이다.
# 이 때 A는 최소힙으로, 루트노드인 A[0]가 최소값인 형태이다. 후술할 HeapifyDown함수를 적용하기 위해서는 이 A[0]를 가장 마지막 원소이자 가장 큰 값을 가지는 리프노드 A[len(A)-1]과 위치를 바꿔야 한다.
# 이렇게 위치가 바뀐 뒤에 리스트의 가장 끝으로 간 A[0], 즉 최솟값은 pop연산을 통해 사라지고 현재 힙은 HeapifyDown함수를 통해 남은 원소 중 가장 작은 값을 A[0]의 위치로 보내고 원소들이 최소힙 성질을 만족하도록 한다.(최소힙 성질은 부모 노드의 키값이 자식 노드의 키값보다 같거나 작은 성질이다.)
# 이를 입력한 수 k보다 1 작은 횟수 만큼 반복을 하는데, 이는 반복횟수를 의미하는 지역변수 i가 0부터 시작하는 이유도 있고 만약 k만큼 반복을 하면 뒤의 pop 연산 때문에 정작 반환해야 할 해당 차례의 A[0]값이 없어지기 때문이기도 하다.

# 2.HeapifyDown 함수의 설명
# HeapifyDown의 역할은 매개변수로 들어온 리스트 A가 최소힙 성질을 만족하도록 원소를 재배열 하는 것이다.
# 매개변수로 힙으로 만들 리스트 하나와 변수 k를 받는데, 위 경우 변수 k는 루트노드의 인덱스인 0이다. 이는 solve함수에서 HeapifyDown 함수 이전에 최솟값과 최댓값의 위치가 바뀌었기에 최소힙에서 가장 작은 원소가 자리했어야 할 루트노드 A[0]에 가장 큰 원소인 A[len(A)-1]이 자리했기 때문이다. A[0]에 자리한 이 원소를 제자리로 돌려보내야 하기 때문에 k=0이 되는 것이다.
# 이렇게 두 가지를 매개변수로 받은 HeapifyDown은 내부에서 반복문을 실행하는데, 반복문은 2*k+1이 전체 원소의 개수보다 작은 동안 실행한다. 
# 이는 2*k+1이 k번째 노드의 왼쪽자식노드의 인덱스를 의미하는데 이것이 len(A)를 이상이라는 것은 리스트의 인덱스를 벗어나는 것이기 때문에 있을 수 없기 때문이다.
# 이 조건이 유지되는 동안 함수는 부모노드(k인덱스를 가지는 원소)와 자식노드들 사이에 어떤 인덱스의 원소가 가장 최솟값을 갖는지 찾는다.
# 그렇게 찾아진 최솟값의 인덱스는 m이라는 새로운 변수에 저장된다. 가장 작은 원소가 힙의 가장 위에 있어야 한다는 최소힙의 특성상 이렇게 찾아진 최솟값의 인덱스 m은 k와 일치해야 한다.
# 그래서 일치하면 break를 통해 반복문을 중단하고 일치하지 않으면 m인덱스의 값과 k인덱스의 값을 바꿔주는 조치를 취한다. 덩달아 이 과정에서 k는 늘 최솟값의 인덱스여야 하므로 k는 m이 k가 되었든 L이 되었든 R이 되었든 상관없이 m으로 바꿔주어야 한다.
# 이 과정을 통해 리스트 A는 최소힙의 성질을 만족하게 된다.


# 위 과정을 의사코드로 대략적으로 나타내면 다음과 같다.

# def solve(A,k):
# 	입력한 횟수 k보다 1 작은 횟수동안 
# 	1.루트노드A[0]과 마지막 리프노드A[len(A)-1]을 스왑(swap)한다.
# 	2.1에서 swap을 통해 말단으로 보내진 최솟값을 pop 한다
# 	3.리스트의 남은 요소들이 최소힙 형태를 유지하도록 조치를 취한다.(HeapifyDown)
# 	4.반복횟수가 k-1번째가 되었다면 반복문을 빠져나와 k번째로 작은 수가 있는 노드인 A[0]을 반환 한다

# -수행시간 분석-

# 1.HeapifyDown의 수행시간
# HeapifyDown에서는 인덱스 k를 가지는 원소가 밑으로 내려가면서 최악의 경우 리프노드까지 내려갈 수도 있다. 한 번 내려갈 때마다 비교횟수는 상수시간(C)이나 루트노드에서 리프노드까지 내려가는 최악의 경우에는 힙의 높이만큼 이를 반복해야 한다. 이진트리에서 힙의 높이는 log2의n이다. 따라서 HeapifyDown의 수행시간은 O(log2의n)이 된다.
# 2.solve의 수행시간
# solve함수가 실행되는 수행시간에 있어 최악의 경우는 n개의 원소가 있는 리스트에서 n번째에 있는 원소를 찾는 경우이다. 이 경우 for문 내의 비교, 대입, pop연산은 한 번 진행하는 데 상수시간이 걸리나 HeapifyDown 연산의 경우 O(log2의n)시간이 걸린다. 이를 감안해 solve함수의 수행시간을 빅오표기법으로 나타내면 n x log n 이므로 O(nlogn)의 시간이 걸린다.
# 전체코드의 수행시간은 상수시간이 걸리는 연산을 제외하고 heaqp.heapify(), solve() 의 수행시간을 더한 것이므로  n + nlogn이 된다. 이는 빅오표기법으로 O(nlogn)이 된다.

# -다른 알고리즘과의 장,단점 비교-
# 여기서 구현한 알고리즘은 힙정렬 방식이다. 이 방식은 이진트리와 최소 또는 최대힙의 성질을 이용해 n개의 원소 하나하나가 아니라 부모-자식간의 관계로 이루어진 원소들로 비교적 빠른 정렬을 하는 것이 가능하다는 장점이 있다. 한 예로 selection 알고리즘에서는 어떤 알고리즘을 쓰더라도 n개의 원소에서 최댓값을 찾아 반환하는 것이 n-1번의 비교를 요구하기 때문에 결과적으로 O(n^2)의 수행시간이 걸리지만 힙정렬에서는 힙을 사용해 이를 O(nlogn)번 만에 하는 것이 가능하다. 또한 힙정렬은 삽입과 삭제,최댓값 또는 최솟값 탐색연산에 특화되어 O(logn) 혹은 O(1)만에 해당 연산들을 하는 것이 가능하다.
# 그러나 이 알고리즘에서 특정 키값을 효율적으로 찾길 기대하기는 힘들다. 어떤 키값을 힙에서 찾는다고 할 때, 이 키값이 왼쪽 자식노드에 있는지 오른쪽 자식노드에 있는지 알 수가 없기 때문이다.
# 항상 수행시간이 O(nlogn)이 보장된다는 점에서 최악의 경우 실행시간이 기본정렬이나 Quick정렬보다 빠르며 MoM알고리즘보다 안정적이라는 장점도 있다.